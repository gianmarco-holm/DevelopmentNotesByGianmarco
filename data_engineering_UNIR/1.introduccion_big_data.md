# Introducci√≥n a las tecnolog√≠as big data

## Introducci√≥n y objetivos
---

Empezaremos la asignatura motivando los contenidos que se estudiar√°n en el resto del temario. Repasaremos las necesidades de la sociedad de la informaci√≥n en la actualidad, una era en la que todos estamos interconectados y somos fuentes de datos. Veremos los retos tecnol√≥gicos que esto supone y presentaremos formalmente las tecnolog√≠as que los solventan.

Los objetivos que persigue este tema son:

* Comprender cu√°les son las necesidades actuales de procesamiento de datos, sus causas y c√≥mo son solventadas por las tecnolog√≠as big data.
* Entender el concepto de cl√∫ster de ordenadores y cu√°les son las principales tecnolog√≠as distribuidas capaces de explotarlo.
* Conocer las herramientas principales que componen el ecosistema Hadoop, cu√°l es la finalidad de cada una y c√≥mo se relacionan entre s√≠.

## La sociedad interconectada: la era del cliente
---
Las tecnolog√≠as big data surgen para dar respuesta a las nuevas necesidades de la sociedad actual. Vivimos en un mundo interconectado, en el que el 90‚Äâ% de la informaci√≥n existente, preservada en medios de cualquier tipo, se ha creado en los √∫ltimos dos a√±os. El crecimiento de la informaci√≥n producida en el mundo por fuentes de todo tipo, tanto f√≠sicas como electr√≥nicas, es exponencial de un tiempo a esta parte. Aunque las estimaciones acerca del volumen divergen, la siguiente gr√°fica muestra de manera orientativa este fen√≥meno.

Casi el 80‚Äâ% de los datos que se crean son generados por personas y, por ello, suelen ser datos no estructurados (texto libre, comentarios de personas, tuits, im√°genes, sonidos, v√≠deos). Los 20‚Äâ% restantes son datos estructurados generados por m√°quinas [datos de logs, sensores, Internet de las cosas (IoT), en general] con el fin de ser procesados generalmente por otras m√°quinas.

### **Fuentes de datos en la actualidad**

Existen principalmente tres tipos de situaciones que generan datos en la actualidad:

* **La interacci√≥n entre humanos** a trav√©s de un sistema inform√°tico que registra informaci√≥n mientras se produce la interacci√≥n. Ejemplos claros son el correo electr√≥nico, los foros de Internet o las redes sociales, donde los datos los generamos los humanos al interactuar entre nosotros utilizando dichos medios. Suelen ser datos no estructurados, posteriormente procesados por m√°quinas.
* **La interacci√≥n entre un humano y una m√°quina.** El ejemplo m√°s claro es la navegaci√≥n en Internet: los servidores web generan logs con informaci√≥n sobre el proceso de navegaci√≥n. Lo mismo ocurre al efectuar compras en alguna plataforma web de comercio electr√≥nico o en banca online, donde cada una de nuestras transacciones queda registrada y ser√° procesada despu√©s con el objetivo de estudiar nuestro comportamiento, as√≠ como de ofrecernos productos mejores y m√°s personalizados. Tienden a ser datos estructurados o semiestructurados.
* **La interacci√≥n entre m√°quinas.** Varias m√°quinas intercambian informaci√≥n y la almacenan con el objetivo de ser procesada por otras m√°quinas. Un ejemplo son los sistemas de monitorizaci√≥n, en los que un sistema de sensores suministra la informaci√≥n recibida a otras m√°quinas para que realicen alg√∫n procesado sobre los datos. Al ser la propia m√°quina quien la genera, suele ser informaci√≥n estructurada, ya que el software se encarga de sistematizarla.

### **La transformaci√≥n digital en relaci√≥n con los datos**

La conclusi√≥n global a la que llegamos es que el mundo ya ha cambiado, y lo podemos confirmar si examinamos hechos como los siguientes:

* La empresa que transporta a m√°s personas en el mundo es Uber, que tiene 0 coches f√≠sicos.
* La empresa que m√°s habitaciones reserva es Airbnb, que tiene 0 hoteles f√≠sicos.
* La empresa que m√°s m√∫sica vende es Spotify, que tiene 0 estudios de grabaci√≥n.
* La empresa que vende m√°s pel√≠culas es Netflix, que tiene 0 estudios.

Con frecuencia, se llevan a cabo m√°s interacciones digitales que f√≠sicas entre las personas y las compa√±√≠as que nos dan servicio, ya sea de suministro de energ√≠a, agua o gas; de telecomunicaciones o telefon√≠a; de venta online de productos de todo tipo, o incluso de movimientos y servicios bancarios. Estas interacciones est√°n generando, de forma continuada y masiva, datos muy valiosos que hablan del comportamiento de los clientes y su an√°lisis permite anticipar qu√© es lo que estos van a demandar. De hecho, estamos evolucionando m√°s r√°pido que las propias compa√±√≠as, hasta el punto de que se ha abierto una brecha entre las empresas f√≠sicas tradicionales y los gigantes digitales, como muestra la figura 2.

Con el objetivo de llenar este espacio, surge la ``transformaci√≥n digital``, que persigue esencialmente tres objetivos:

* **Centrarse en el cliente**, es decir, pensar continuamente en lo que necesita y en mejorar (personalizar) su experiencia y sus interacciones con la compa√±√≠a. Esto requiere recabar y analizar grandes cantidades de datos sobre su comportamiento.
* **Centrarse en canales digitales**, especialmente dispositivos m√≥viles, puesto que las interacciones digitales son las que generan mayor cantidad de datos y, cada vez con m√°s frecuencia, se realizan usando estos dispositivos en vez del PC.
* **Decisiones guiadas por los datos (data-driven)**, para lo cual es necesaria la ciencia de (grandes) datos (big data science).

# **¬øQu√© es Big Data?**
Big Data se refiere al **conjunto de datos masivos y complejos** que no pueden ser gestionados, procesados ni analizados con herramientas tradicionales debido a su gran volumen, velocidad y variedad. Se utiliza en diversas √°reas como inteligencia artificial, negocios, salud y m√°s para obtener **informaci√≥n valiosa y tomar mejores decisiones**.

---

## **Las 3V del Big Data**
Las 3V son los tres pilares fundamentales que caracterizan al Big Data:

### **1. Volumen üìä**  
- Se refiere a la **gran cantidad de datos** generados cada segundo por diversas fuentes (redes sociales, sensores, transacciones, dispositivos IoT, etc.).  
- **Ejemplo:** Facebook genera m√°s de **4 petabytes de datos al d√≠a**.

### **2. Velocidad ‚ö°**  
- Es la rapidez con la que los datos son generados, procesados y analizados en tiempo real o casi en tiempo real.  
- **Ejemplo:** Aplicaciones como **Google Maps** procesan datos de tr√°fico en segundos para ofrecer rutas √≥ptimas.

### **3. Variedad üîÑ**  
- Representa la diversidad de formatos de datos: **estructurados** (bases de datos), **no estructurados** (videos, im√°genes, texto) y **semiestructurados** (JSON, XML).  
- **Ejemplo:** Los datos de **correos electr√≥nicos, tweets y sensores de temperatura** tienen formatos diferentes.

## **Origen de las Tecnolog√≠as Big Data**
---
**Google y el Auge del Big Data**

La primera empresa que identific√≥ el crecimiento exponencial de los datos en Internet fue **Google**, debido a la necesidad de su buscador de indexar nuevas p√°ginas web. 

### **Google File System (GFS)**
En **2003**, **Sanjay Ghemawat, Howard Gobioff y Shun-Tak Leung** publicaron un art√≠culo sobre **Google File System (GFS)**, un sistema de archivos distribuido que permit√≠a almacenar grandes vol√∫menes de datos en un cl√∫ster de ordenadores convencionales. 

- Se introdujo el concepto de **commodity hardware**, donde varias m√°quinas de bajo costo trabajan juntas como una sola.
- **GFS** sirvi√≥ como base para **HDFS (Hadoop Distributed File System)**.

### **MapReduce y la Programaci√≥n en Cl√∫steres**
En **2004**, **Jeffrey Dean y Sanjay Ghemawat** presentaron el modelo de programaci√≥n **MapReduce**, dise√±ado para procesar grandes archivos en paralelo dentro de un cl√∫ster de ordenadores.

- **Ventaja clave**: Abstracci√≥n de hardware, redes y comunicaci√≥n entre nodos, facilitando el desarrollo de aplicaciones distribuidas.
- Durante a√±os, **MapReduce fue el est√°ndar de software Big Data** en el √°mbito comercial.

### **El Nacimiento de Apache Spark**
En **2009**, debido a las limitaciones de Hadoop, **Matei Zaharia** cre√≥ **Apache Spark** como parte de su tesis doctoral en **Berkeley**.

- Spark mantiene los principios de **ejecuci√≥n en cl√∫steres de commodity hardware**.
- Simplifica los procesos de redes y comunicaci√≥n entre nodos.
- Desde **2014**, **Spark ha reemplazado completamente a MapReduce**.

Muchas herramientas que usaban MapReduce han evolucionado y adoptado **Spark** como motor de ejecuci√≥n, asegurando su relevancia en el ecosistema Big Data actual.

## **El Ecosistema Hadoop**
---

### **Procesamiento Distribuido**
Las tecnolog√≠as de procesamiento distribuido permiten manejar grandes vol√∫menes de datos mediante m√∫ltiples m√°quinas interconectadas en un **cl√∫ster**.

- Se utiliza **commodity hardware** (m√°quinas de bajo costo pero altamente escalables).
- Para aumentar la capacidad de procesamiento o almacenamiento, simplemente se a√±aden m√°s nodos al cl√∫ster.

### **Hadoop y su Filosof√≠a**
Siguiendo esta idea y bas√°ndose en **Google File System (GFS)**, naci√≥ **Hadoop**, que incorpor√≥:

- **HDFS (Hadoop Distributed File System)**: Sistema de archivos distribuido.
- **MapReduce**: Paradigma de programaci√≥n para procesamiento paralelo.

### **Ecosistema Hadoop**
A partir de Hadoop, se desarroll√≥ un conjunto de herramientas **open source** dise√±adas para procesamiento distribuido. 
Cada una cumple un prop√≥sito espec√≠fico, pero todas pueden interoperar dentro del ecosistema Hadoop.

Sin intentar ser exhaustivos y a t√≠tulo meramente informativo, damos una breve descripci√≥n de cada una:

* **HDFS:** sistema de archivos distribuido que estudiaremos en el tema siguiente.
* **MapReduce:** paradigma de programaci√≥n para un cl√∫ster de ordenadores (forma de estructurar programas y tambi√©n biblioteca de programaci√≥n que se ejecuta sobre el cl√∫ster). Actualmente ha ca√≠do en desuso.
* **Flume:** herramienta para tratamiento de logs.
* **Sqoop:** herramienta para migraci√≥n de grandes cantidades de datos desde bases de datos convencionales a HDFS.
* **Zookeeper:** coordinador.
* **Oozie:** herramienta para planificaci√≥n y ejecuci√≥n de flujos de datos.
* **Pig:** herramienta para programar flujos de datos con sintaxis similar a SQL, pero con mayor nivel de granularidad, cuyo procesamiento se efect√∫a con MapReduce.
* **Mahout:** biblioteca de algoritmos de machine learning. Originalmente programada con MapReduce, ten√≠a un rendimiento pobre, pero actualmente soporta otros backend como Spark.
* ** R Connectors:** herramientas para conectar MapReduce con el lenguaje de programaci√≥n R. En desuso, al igual que MapReduce.
* **Hive:** herramienta para manejar datos almacenados en HDFS utilizando lenguaje SQL. En su origen, utilizaba MapReduce como motor de ejecuci√≥n. Actualmente soporta Spark y Apache Tez.
* **HBase:** base de datos NoSQL de tipo columnar, que permite, entre otras cosas, tener registros (filas) de longitud y n√∫mero de campos variable.

En este curso, nos centraremos en las siguientes herramientas de Apache, que constituyen el est√°ndar tecnol√≥gico de facto en la mayor√≠a de las empresas que utilizan tecnolog√≠as big data:

* **HDFS (Hadoop Distributed File System):** sistema de archivos distribuido inspirado en el GFS de Google, que permite distribuir los datos entre distintos nodos de un cl√∫ster, gestionando la distribuci√≥n y la redundancia de forma transparente para el desarrollador que vaya a hacer uso de esos datos.
* **Apache Hive:** herramienta para acceder mediante sintaxis SQL a datos estructurados que est√°n almacenados en un sistema de archivos distribuido, como HDFS u otros similares. Las consultas SQL son traducidas autom√°ticamente a trabajos de procesamiento distribuido seg√∫n el motor que se haya configurado, que puede ser MapReduce, Apache Spark o Apache Tez.
* **Apache Spark:** motor de procesamiento distribuido y bibliotecas de programaci√≥n distribuida de prop√≥sito general, que opera siempre en la memoria principal (RAM) de los nodos del cl√∫ster. Desde hace unos a√±os, ha reemplazado totalmente a MapReduce al ser mucho m√°s r√°pido.
* **Apache Kafka:** plataforma para manejo de eventos en tiempo real, que consiste en una cola de mensajes distribuida y masivamente escalable sobre un cl√∫ster de ordenadores. Estos mensajes pueden ser consumidos por uno o varios procesos externos (por ejemplo, trabajos de Spark).

## **Distribuciones de Hadoop**
---

Hadoop est√° compuesto por m√∫ltiples herramientas que requieren instalaci√≥n y configuraci√≥n individual dentro de un **cl√∫ster**. Este proceso era complejo y demandaba conocimientos avanzados. Para simplificarlo, surgieron las **distribuciones de Hadoop**, que agrupan herramientas compatibles y preconfiguradas en un solo paquete de software, eliminando la necesidad de instalarlas por separado.

### **Empresas y Distribuciones de Hadoop**
Varias empresas desarrollaron distribuciones de Hadoop, a√±adiendo herramientas propietarias y mejorando el c√≥digo fuente original:

- **Cloudera**
- **Hortonworks** (fusionada con Cloudera en 2018)
- **MapR**

Cada una ofrece versiones **open source** y de **pago**, con diferentes caracter√≠sticas:

| **Distribuci√≥n** | **Componentes**              | **Versiones**               | **Sistema Operativo**      | **A√±o de Creaci√≥n** | **Notas**                                    |
| ---------------- | ---------------------------- | --------------------------- | -------------------------- | ------------------- | -------------------------------------------- |
| **Cloudera**     | Apache modificado y a√±adidos | Open source (CDH) y de pago | Linux (Windows v√≠a VMWare) | 2008                | La m√°s extendida. Certificaci√≥n muy popular. |
| **Hortonworks**  | Solo Apache oficiales        | 100% open source            | Linux y Windows            | 2011                | √önica 100% open source.                      |
| **MapR**         | Apache y a√±adidos            | Open source y de pago       | Linux (Windows v√≠a VMWare) | 2009                | La m√°s r√°pida y f√°cil de instalar.           |

Las distribuciones de Hadoop han facilitado su adopci√≥n en empresas al reducir la complejidad de instalaci√≥n y ofrecer soporte profesional.