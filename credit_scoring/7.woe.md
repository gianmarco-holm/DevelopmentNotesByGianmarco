# An√°lisis WOE

## 1. WOE (Weight of Evidence)
---

El **Weight of Evidence (WoE)** es un indicador estad√≠stico que mide qu√© tan bien una categor√≠a de una variable discrimina entre clientes que cayeron en default ($ Default = 1 $) y aquellos que no ($ Default = 0 $).

**F√≥rmula del WoE:**

Para cada categor√≠a $ i $:

$$
WoE_i = \ln\left(\frac{\text{\% Buenos en la categor√≠a } i}{\text{\% Malos en la categor√≠a } i}\right)
$$

Donde:
- $ \text{\% Buenos} $: Proporci√≥n de clientes buenos ($ Default = 0 $) en la categor√≠a.
- $ \text{\% Malos} $: Proporci√≥n de clientes malos ($ Default = 1 $) en la categor√≠a.

### üìåCaracter√≠sticas del WoE

1. Si $ WoE > 0 $: La categor√≠a tiene mayor proporci√≥n de buenos (no morosos).
2. Si $ WoE < 0 $: La categor√≠a tiene mayor proporci√≥n de malos (morosos).
3. Si $ WoE = 0 $: La categor√≠a tiene proporciones iguales de buenos y malos.

### Ejemplo: WoE por Nivel de Ingresos

| Nivel de Ingresos   | Total Clientes | Clientes Buenos ($ Default = 0 $) | Clientes Malos ($ Default = 1 $) |
|----------------------|----------------|-------------------------------------|-------------------------------------|
| Bajo                | 100            | 20                                  | 80                                  |
| Medio               | 300            | 240                                 | 60                                  |
| Alto                | 200            | 190                                 | 10                                  |

**Paso 1: Calcular \% Buenos y \% Malos**

| Nivel de Ingresos   | \% Buenos ($ \frac{\text{Buenos en la categor√≠a}}{\text{Total Buenos}} $) | \% Malos ($ \frac{\text{Malos en la categor√≠a}}{\text{Total Malos}} $) |
|----------------------|---------------------------------------------|---------------------------------------------|
| Bajo                | $ \frac{20}{450} = 0.044 $               | $ \frac{80}{150} = 0.533 $               |
| Medio               | $ \frac{240}{450} = 0.533 $              | $ \frac{60}{150} = 0.400 $               |
| Alto                | $ \frac{190}{450} = 0.422 $              | $ \frac{10}{150} = 0.067 $               |

**Paso 2: Calcular WoE**

| Nivel de Ingresos   | \% Buenos | \% Malos | WoE ($ \ln\left(\frac{\text{\% Buenos}}{\text{\% Malos}}\right) $) |
|----------------------|----------|---------|------------------------------------------------------|
| Bajo                | 0.044    | 0.533   | $ \ln\left(\frac{0.044}{0.533}\right) = -3.14 $   |
| Medio               | 0.533    | 0.400   | $ \ln\left(\frac{0.533}{0.400}\right) = 0.29 $    |
| Alto                | 0.422    | 0.067   | $ \ln\left(\frac{0.422}{0.067}\right) = 2.03 $    |

### Interpretaci√≥n del WoE:

1. **Nivel de ingresos bajo**: $ WoE = -3.14 $, indicando un alto riesgo de default. La proporci√≥n de malos es mucho mayor que la de buenos.
2. **Nivel de ingresos medio**: $ WoE = 0.29 $, mostrando un riesgo cercano al promedio, con proporciones similares entre buenos y malos.
3. **Nivel de ingresos alto**: $ WoE = 2.03 $, indicando bajo riesgo de default. La proporci√≥n de buenos es significativamente mayor.

### Relaci√≥n con el Credit Scoring:

- El WoE transforma variables categ√≥ricas o continuas en datos num√©ricos, facilitando el modelado estad√≠stico.
- Ayuda a identificar variables con buena capacidad discriminativa.
- Es un componente clave en modelos de regresi√≥n log√≠stica y otros m√©todos utilizados en **credit scoring**.

## 2. Categorizar variables categoricas
---

Un √°rbol de decisi√≥n ayuda a clasificar una variable que mejor separe los buenos de los malos como por ejemplo **edad** dividiendo los datos en ramas basadas en condiciones l√≥gicas. 

1. **Divisi√≥n por reglas**: 
   El √°rbol eval√∫a puntos de corte ($ thresholds $) en la variable edad. Por ejemplo:
   - Si $ \text{Edad} \leq 30 $: Mayor probabilidad de ser **mal pagador** ($ Default = 1 $).
   - Si $ \text{Edad} > 30 $: Mayor probabilidad de ser **buen pagador** ($ Default = 0 $).

2. **Criterio de divisi√≥n**: 
   Las divisiones se realizan utilizando m√©tricas como la **entrop√≠a** o el **√≠ndice de Gini**, para maximizar la separaci√≥n entre las categor√≠as.

$$
\text{Gini} = 1 - \sum_{i=1}^{n}p_i^2
$$
Donde:
- $ p_i $: Proporci√≥n de observaciones en la categor√≠a $ i $.

**Representaci√≥n del √Årbol**

```plaintext
                Edad
               /    \
        Edad ‚â§ 25   Edad > 25
         /               \
    Default = 1     Edad ‚â§ 45
                      /    \
               Default = 0  Edad > 45
                            /
                     Default = 0
```

## 3. Arboles de decisi√≥n con ctree
---

```R
#install.packages("smbinning", dependencies = T)
#install.packages("party")
library(smbinning)
library(party)

#ojo Smbinning no acepta nombre Default
#El target en Smninning es 1 = bueno
train$BUENO = ifelse(train$Default == 1,0,1) 

# Var Experiencia
plot(ctree( as.factor(Default) ~ Experiencia, train)) #pvalue = la prop de malos son iguales en las ramas sgts

```

## 4. Interpretaci√≥n WOE

Para ello visitaremos la siguiente [p√°gina](https://ucanalytics.com/blogs/information-value-and-weight-of-evidencebanking-case/), donde usaremos el siguiente [excel](./recursos/WOE.xlsx).

Con este excel podremos obtener la `Information Value` que en nos ayudar√° a la selecci√≥n de variables para el modelo en base a este cuadro 

| **Valor de la Informaci√≥n (IV)** | **Poder Predictivo**                       |
|-----------------------------------|-------------------------------------------|
| < 0.02                            | In√∫til para la predicci√≥n                 |
| 0.02 a 0.1                        | Predictor d√©bil                           |
| 0.1 a 0.3                         | Predictor medio                           |
| 0.3 a 0.5                         | Predictor fuerte                          |
| > 0.5                             | Sospechoso o demasiado bueno para ser verdad |

## 5. Algoritmo de R para WOE

Utilizamos machine learning para la clasificar las variables y obtener tanto el WOE como el IV

```R
#install.packages("smbinning", dependencies = T)
#install.packages("party")
library(smbinning)
library(party)

#Smbinning crea intervalos de la variable "Experiencia", m√©tricas como el WoE (Weight of Evidence) y el IV (Information Value).
smb_EXP = smbinning(train,y= "BUENO",x="Experiencia",p = 0.05)
smb_EXP$ivtable
# Se grafica las m√©tricas principales
par(mfrow = c(2,2))
smbinning.plot(smb_EXP,option="dist",sub="Experiencia")
smbinning.plot(smb_EXP,option="badrate",sub="Experiencia") 
smbinning.plot(smb_EXP,option="goodrate",sub="Experiencia")
smbinning.plot(smb_EXP,option="WoE",sub="Experiencia")
```

## 6. Otra metodolog√≠a para WOE

```R
tabla_woe = function(x_cat, y) {
   Tabla=table(x_cat, y)
   DF_WOE=data.frame(malos=Tabla[,2],buenos=Tabla[,1])
   DF_WOE$buenos_prop = DF_WOE$buenos/sum( DF_WOE$buenos)
   DF_WOE$malos_prop = DF_WOE$malos/sum( DF_WOE$malos)
   DF_WOE$WOE=log(DF_WOE$buenos_prop/DF_WOE$malos_prop)
   DF_WOE$IV=(DF_WOE$buenos_prop - DF_WOE$malos_prop)*DF_WOE$WOE
   DF_WOE
}

tabla_woe(train$Educacion, train$Default)
tabla_woe(train$Sexo, train$Default)
tabla_woe(train$Tipo_Empleo, train$Default)
tabla_woe(train$Estado_civil, train$Default)
tabla_woe(train$Numero_entidades, train$Default)
```

