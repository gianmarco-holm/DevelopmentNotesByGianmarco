# Probabilidad

## 1. Incertidumbre y Probabilidad
---

### 1.1. ¿Qué es la probabilidad?

_La probabilidad siempre se usa en situaciones donde hay incertidumbre ( Aparece cuando la toma de decisiones se hace dificil por falta de información )._<br>
_La probabilidad es un lenguaje que nos da la herramienta para cuantificar la incertidumbre._

$
P(A)= \frac {Número de resultados favorables para A}{Número total de resultados posibles}
$

**Un axioma:**

Es una afirmación o proposición que se acepta como verdadera sin necesidad de demostración. Es la base sobre la cual se construyen teorías y argumentos. En matemáticas, los axiomas son los principios fundamentales que no se cuestionan y sirven como punto de partida para derivar otros resultados.

**Axionas de probabilidad:**

- $0 \leq P \leq 1$
- $certeza -> P = 1$
- $imposibilidad -> P = 0$
- $disjuntos -> P(A U B) = P(A) + P(B)$<br>

**Diferencia entre escuela bayesiana y frecuentista:**

Las dos escuelas principales en estadística son la bayesiana y la frecuentista, y se diferencian en cómo interpretan la probabilidad:

- **Frecuentista:** La probabilidad se define como la frecuencia relativa de un evento en ensayos repetidos. Por ejemplo, si lanzas un dado muchas veces, la probabilidad de obtener un 6 se estima observando cuántas veces aparece 6 en un número grande de lanzamientos. No se utilizan creencia o información previa.

- **Bayesiana:** La probabilidad se interpreta como un grado de creencia o confianza en un evento basado en información previa. Los bayesianos actualizan sus creencias a medida que obtienen nueva información, utilizando el Teorema de Bayes. Esto significa que, para ellos, la probabilidad puede cambiar a medida que se adquiere más evidencia.

En resumen, los frecuentistas se centran en datos empíricos y repeticiones, mientras que los bayesianos consideran la probabilidad como una medida subjetiva que puede adaptarse con nueva información.

---

### 1.2. Probabilidad en machine learning

**Fuentes de inceridumbre:**

- **Datos:** Debido a que nuestros instrumentos de medición tienen un margen de error, se presentan datos imperfectos e incompletos, por lo tanto hay incertidumbre en los datos.
- **Atributos del modelo:** Son variables que representan un subconjunto reducido de toda la realidad del problema, estas variables provienen de los datos y por lo tanto presentan cierto grado de incertidumbre.
- **Arquitectura del modelo:** Un modelo en mates es una representación simplificada de la realidad y al ser así, por construcción, induce otra capa de incertidumbre, ya que al ser una representación simplificada se considera mucho menos información.

`Y toda esta incertidumbre se puede cuantificar con probabilidad`

## 2. Fundamentos de la probabilidad

### 2.1. Tipos de probabilidad 
</br>

#### 1. Probabilidad Conjunta:

_La probabilidad conjunta de dos eventos, denotada como $ P(A \cap B) $, es la probabilidad de que ambos eventos $ A $ y $ B $ ocurran al mismo tiempo. Se aplica principalmente en contextos en los que se quiere estudiar la relación entre dos eventos. La probabilidad conjunta se calcula de la siguiente forma:_

$$
P(A \cap B) = P(A) \cdot P(B \,|\, A)
$$

_donde $ P(B \,|\, A) $ es la **probabilidad condicional** de que ocurra $ B $ dado que ya ha ocurrido $ A $. Si los eventos $ A $ y $ B $ son **independientes** (uno no afecta al otro), entonces la probabilidad conjunta se simplifica a:_

$$
P(A \cap B) = P(A) \cdot P(B)
$$

#### 2. Probabilidad Marginal

_La probabilidad marginal de un evento, denotada como $ P(A) $, es simplemente la probabilidad de que ocurra el evento sin considerar la ocurrencia de otros eventos. Es útil en el análisis de eventos individuales en un conjunto de eventos más amplio. Si se tiene una probabilidad conjunta de varios eventos, la probabilidad marginal se obtiene sumando las probabilidades conjuntas que incluyen el evento de interés:_

$$
P(A) = \sum_{B} P(A \cap B)
$$

#### 3. Probabilidad Condicional

_La probabilidad condicional de un evento $ B $ dado que ocurrió otro evento $ A $, denotada como $ P(B \,|\, A) $, mide la probabilidad de que ocurra $ B $ bajo la condición de que $ A $ ya ha sucedido. Se calcula con la fórmula:_

$$
P(B \,|\, A) = \frac{P(A \cap B)}{P(A)}
$$

_Esta probabilidad se utiliza cuando el hecho de que ocurra un evento depende de que haya ocurrido otro._

>Ejemplo

Imaginemos una baraja de cartas, y queremos encontrar la probabilidad de sacar una carta de corazones y que sea un número par.

- Si consideramos **probabilidad conjunta**: sería la probabilidad de que ocurra el evento de sacar una carta de corazones y, a la vez, que sea un número par (2, 4, 6, 8 o 10 de corazones).
- Si analizamos la **probabilidad marginal** de sacar una carta de corazones, no consideraríamos si la carta es par o no, solo si es de corazones.
- Para la **probabilidad condicional**, podríamos querer saber, por ejemplo, la probabilidad de que la carta sea par dado que ya sabemos que es de corazones.

---

### 2.2. Ejemplos de cálculo de probabilidad

>Ejemplo 1: Probabilidad Básica

Supongamos que lanzamos un dado de seis caras y queremos encontrar la probabilidad de obtener un número par. Los resultados posibles en un dado de seis caras son: $ \{1, 2, 3, 4, 5, 6\} $. Los resultados favorables para obtener un número par son $ \{2, 4, 6\} $.

Entonces, la probabilidad de obtener un número par $ P(\text{par}) $ es:

$$
P(\text{par}) = \frac{\text{Número de resultados favorables}}{\text{Número total de resultados posibles}} = \frac{3}{6} = 0.5
$$

>Ejemplo 2: Probabilidad Conjunta

Consideremos una baraja de cartas estándar de 52 cartas. Queremos calcular la probabilidad de sacar una carta que sea tanto de corazones como un número par.

En una baraja de cartas, hay 13 cartas de corazones y de estas, 5 son números pares (2, 4, 6, 8 y 10).

La probabilidad conjunta de que la carta sea de corazones y de un número par, denotada como $ P(\text{corazones} \cap \text{par}) $, es:

$$
P(\text{corazones} \cap \text{par}) = \frac{\text{Número de cartas de corazones pares}}{\text{Número total de cartas}} = \frac{5}{52} \approx 0.096
$$

>Ejemplo 3: Probabilidad Marginal

Siguiendo el ejemplo de la baraja de cartas, ahora calculemos la probabilidad marginal de que la carta sea de corazones, sin importar si es par o impar. En este caso, hay 13 cartas de corazones en una baraja de 52 cartas.

La probabilidad marginal de sacar una carta de corazones, $ P(\text{corazones}) $, es:

$$
P(\text{corazones}) = \frac{\text{Número de cartas de corazones}}{\text{Número total de cartas}} = \frac{13}{52} = 0.25
$$

* Ejemplo 4: Probabilidad Condicional

Ahora, supongamos que hemos sacado una carta de corazones y queremos encontrar la probabilidad de que sea un número par dado que ya sabemos que es de corazones.

La probabilidad condicional de que la carta sea un número par dado que es de corazones, denotada como $ P(\text{par} \,|\, \text{corazones}) $, se calcula como:

$$
P(\text{par} \,|\, \text{corazones}) = \frac{P(\text{par} \cap \text{corazones})}{P(\text{corazones})}
$$

Dado que ya hemos calculado $ P(\text{par} \cap \text{corazones}) = \frac{5}{52} $ y $ P(\text{corazones}) = \frac{13}{52} $, sustituimos:

$$
P(\text{par} \,|\, \text{corazones}) = \frac{\frac{5}{52}}{\frac{13}{52}} = \frac{5}{13} \approx 0.3846
$$

Este resultado indica que, si ya sabemos que la carta es de corazones, la probabilidad de que además sea un número par es aproximadamente $ 0.3846 $.

#### **Ejemplos de Correlación**

_La **correlación** mide la relación o dependencia entre dos variables. Los valores de correlación pueden variar de -1 a 1:_
1. _Una **correlación positiva** indica que ambas variables tienden a aumentar o disminuir juntas._
2. _Una **correlación negativa** indica que una variable tiende a aumentar cuando la otra disminuye y viceversa._

>Ejemplo 5: Correlación Positiva

A = La probabilidad de que salga 4 al lanzar un dado es $ 1/6 = 16\% $ <br>
B = La probabilidad de que salga par es $ 3/6 = 50 \% $

A | B =  La probabilidad de que salga A despues de que haya ocurrido B es $ \frac{P(B \cap A)}{P(B)} = 1 / 3$

> Como vemos La probabilidad de A despues de que haya ocurrido B es de 50% siendo mayor a la probabilidad solo de A de 16%, a eso le llamamos correlación positiva, una correlación negativa sucede lo contrario, la probabilidad de A|B sería menor a la probabilidad de solo de A.

---

### 2.3. Paradoja

En probabilidad, una paradoja es una situación o problema donde el resultado parece contradictorio o va en contra de la intuición, a pesar de estar basado en principios matemáticos sólidos. Este tipo de paradojas ilustra cómo la intuición humana puede fallar al intentar entender situaciones probabilísticas complejas. A continuación, te presento algunas paradojas famosas en probabilidad que ayudan a entender estos conceptos.

1. Paradoja de Monty Hall:

La paradoja de Monty Hall proviene de un juego donde tienes tres puertas: detrás de una puerta hay un coche y detrás de las otras dos puertas hay cabras. El juego consiste en elegir una puerta. Después de tu elección, el presentador, que sabe lo que hay detrás de cada puerta, abre otra puerta que tiene una cabra y te ofrece la opción de cambiar tu elección inicial a la otra puerta cerrada.

Paradoja: Aunque parece que cambiar o no debería dar las mismas probabilidades (50%), la probabilidad de ganar el coche aumenta si cambias. Matemáticamente, al cambiar, tienes una probabilidad de 2/3 de ganar, mientras que si te quedas con tu elección inicial, solo tienes 1/3.

2. Paradoja de Simpson:

La paradoja de Simpson ocurre cuando una tendencia presente en varios grupos de datos desaparece o se revierte al combinar esos grupos. Esto puede dar lugar a interpretaciones erróneas de los datos y se observa con frecuencia en estudios estadísticos y en análisis de datos.

Ejemplo: Imagina dos tratamientos médicos (A y B) aplicados a dos grupos de pacientes (grupos 1 y 2). Puede ocurrir que el tratamiento A parezca mejor en cada grupo individual, pero al combinar los grupos, el tratamiento B resulta tener una tasa de éxito mayor en conjunto. Esto sucede debido a cómo se distribuyen los datos entre los grupos y muestra cómo las correlaciones pueden ser engañosas.

---

## 3. distribuciones de Probabilidad

---

### 3.1. ¿Qué es una distribución?

Es una función donde relaciona las variables de un espacio muestral con sus probabilidades.

---

### 3.2. Distribuciones discretas

_Una **distribución discreta** describe la probabilidad de los resultados de una variable aleatoria discreta, es decir, una variable que solo puede tomar valores específicos (generalmente enteros). Ejemplos comunes de variables aleatorias discretas incluyen el número de lanzamientos de un dado, el número de aprobados en un examen, etc._

Si $ X $ es una variable aleatoria discreta con posibles valores $ x_1, x_2, \dots, x_n $, y $ P(X = x_i) $ es la probabilidad de que $ X $ tome el valor $ x_i $, entonces:

$$
\sum_{i=1}^{n} P(X = x_i) = 1
$$

Esta suma es igual a 1 porque la probabilidad total de todos los resultados posibles de la variable aleatoria debe cubrir todos los casos posibles.

>Ejemplo de Distribución Discreta

Consideremos el lanzamiento de un dado. La variable aleatoria $ X $ representa el número que aparece en el dado y solo puede tomar valores enteros entre 1 y 6. Si el dado es justo, cada valor tiene una probabilidad de $ \frac{1}{6} $, y la distribución discreta de $ X $ es:

$$
P(X = x) = 
\begin{cases}
\frac{1}{6}, & \text{si } x \in \{1, 2, 3, 4, 5, 6\} \\
0, & \text{si no}
\end{cases}
$$

**Distribución Binomial:**

La **distribución binomial** es un tipo específico de distribución discreta que modela el número de éxitos en una secuencia de $ n $ ensayos independientes de tipo éxito/fallo (prueba de Bernoulli), donde la probabilidad de éxito es constante en cada ensayo.

Si $ X $ es una variable aleatoria que representa el número de éxitos en $ n $ ensayos, y $ p $ es la probabilidad de éxito en cada ensayo, entonces la probabilidad de que $ X $ tome un valor específico $ k $ (es decir, exactamente $ k $ éxitos en $ n $ ensayos) está dada por la función de probabilidad binomial:

$$
P(X = k) = \binom{n}{k} p^k (1 - p)^{n - k}
$$

donde $ \binom{n}{k} $ es el **coeficiente binomial** y se calcula como:

$$
\binom{n}{k} = \frac{n!}{k! (n - k)!}
$$

>Ejemplo de Distribución Binomial

Supongamos que lanzamos una moneda justa (donde la probabilidad de cara es $ p = 0.5 $) 10 veces. Queremos encontrar la probabilidad de obtener exactamente 6 caras.

En este caso:
- $ n = 10 $: número de ensayos.
- $ k = 6 $: número de éxitos deseados (caras).
- $ p = 0.5 $: probabilidad de éxito (cara en cada lanzamiento).

Entonces, aplicamos la fórmula de la distribución binomial:

$$
P(X = 6) = \binom{10}{6} (0.5)^6 (1 - 0.5)^{10 - 6}
$$

Calculamos el coeficiente binomial $ \binom{10}{6} $:

$$
\binom{10}{6} = \frac{10!}{6! \cdot (10 - 6)!} = 210
$$

y sustituimos en la fórmula:

$$
P(X = 6) = 210 \cdot (0.5)^6 \cdot (0.5)^4 = 210 \cdot (0.5)^{10} = 210 \cdot 0.0009765625 \approx 0.205
$$

Por lo tanto, la probabilidad de obtener exactamente 6 caras en 10 lanzamientos es aproximadamente $ 0.205 $.

>Otros tipos de distribuciones discretas:

- Poisson
- Geométrica
- Hipergeométrica
- Binomial negativa

---

### 3.3. Distribución Binomial

[Enlace de Colab](https://drive.google.com/file/d/1vvyR3JZ7r9WOKd3PRvg1VGcEQ4_O25rK/view?usp=sharing)

---

### 3.4. Distribución continua

[Enlace de Colab](https://drive.google.com/file/d/1sfxMVrtlGsEXNVM84LML2O9zvOENXrJ3/view?usp=sharing)

---

### 3.5. ¿Cómo estimar una distribución?

Estimar una distribución de probabilidad implica determinar, a partir de datos observados o de ciertas suposiciones teóricas, una función que represente la probabilidad de ocurrencia de diferentes valores o resultados de una variable aleatoria. El objetivo es encontrar una distribución que se ajuste a los datos y permita modelar y hacer inferencias sobre los patrones de la variable en estudio.

**Métodos de Estimación de una Distribución de Probabilidad**
Para estimar una distribución de probabilidad, se suelen utilizar uno de los siguientes métodos:

1. Métodos Paramétricos:

Consisten en asumir que los datos siguen una distribución específica (como la normal, binomial, exponencial, etc.) y estimar los parámetros de esta distribución (por ejemplo, media y desviación estándar para una distribución normal).
Un método común es el de Máxima Verosimilitud, que encuentra los valores de los parámetros que hacen más probable la ocurrencia de los datos observados.
Otro método es el de Momentos, que iguala los momentos de la muestra (media, varianza) con los momentos de la distribución teórica.

2. Métodos No Paramétricos:

No suponen una forma específica para la distribución. En su lugar, construyen la distribución directamente a partir de los datos.
Un ejemplo es el histograma o el estimador de densidad kernel, que permite crear una aproximación de la distribución de probabilidad de los datos sin imponer una forma particular.

3. Métodos Bayesianos:

En el enfoque bayesiano, se combinan los datos con información previa sobre la distribución (llamada priori) para actualizar las creencias sobre la distribución de probabilidad. Esto se hace usando el Teorema de Bayes.
Es útil cuando se dispone de conocimientos previos que pueden ayudar a estimar la distribución de la variable de interés.

[Enlace de Ejercicio](https://drive.google.com/file/d/19Q7PdsYzKyc8z4rpr2RUGYZpQ0BaOe_J/view?usp=sharing)

---

## 4. MLE (Maximum Likelihood Estimation)

---

### 4.1. MLE (Maximum Likelihood Estimation)

MLE (Maximum Likelihood Estimation) O estimación de máxima verosimilitud. Consiste en escoger la distribucion que más se ajuste a nuestros datos, para ello maximizamos la probabilidad de nuesto modelo: 

$P(X,θ)=L(X,θ)$

$max L(X,θ) → maxΠP(Xi,θ)$

**Nota:** El producto de mútiples probabilidades (por tanto son menores a 1) genera número cada vez más pequeños al punto que no son reconocimos por la máquina, a esto se llama underflow para evitar esta situacion usamos logaritmos:

$max log L(X,θ) → maxΣ log P(Xi,θ)$

---

### 4.1. MLE en machine learning

MLE (Maximum Likelihood Estimation) es un método estadístico utilizado para estimar los parámetros de un modelo de machine learning. En términos simples, el objetivo de MLE es encontrar los valores de los parámetros que hacen que los datos observados sean más probables bajo el modelo. Esto se hace maximizando una función llamada función de verosimilitud.

**Resumido:**

* Se define una función de verosimilitud que representa la probabilidad de observar los datos dados ciertos parámetros.
* Se maximiza esa función con respecto a los parámetros del modelo.
* El resultado es un conjunto de parámetros que mejor ajustan el modelo a los datos observados.

En resumen, MLE busca los parámetros que maximicen la probabilidad de que los datos observados hayan sido generados por el modelo.

---

## 5. Inferencia Bayesiana

---

## 5.1. Teorema de Bayes

El **Teorema de Bayes** es una fórmula que describe cómo actualizar nuestras creencias sobre un evento basado en nueva evidencia. Se utiliza para calcular la probabilidad de un evento **A** dado que ha ocurrido otro evento **B**.

La fórmula es:

$$ P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)} $$

Donde:

- $ P(A|B) $: **Probabilidad posterior** de $ A $ dado $ B $.
- $ P(B|A) $: **Probabilidad de la evidencia** $ B $ dado $ A $.
- $ P(A) $: **Probabilidad previa** de $ A $.
- $ P(B) $: **Probabilidad total** de $ B $, que actúa como una constante de normalización.

En resumen, el Teorema de Bayes nos permite **ajustar nuestras probabilidades previas** a medida que obtenemos **nueva información** (la evidencia).
