# Introducci√≥n a Machine Learning

## 1. Introducci√≥n a Machine Learning

<br>

### 1.1. Machine Learning y sus Tipos

**Machine Learning (ML)** es una rama de la inteligencia artificial que permite a las m√°quinas aprender y mejorar a partir de datos sin ser expl√≠citamente programadas. Se basa en algoritmos que identifican patrones en los datos y hacen predicciones o decisiones autom√°ticas.

#### Tipos de Machine Learning

1. **Aprendizaje Supervisado**  
   - Utiliza datos etiquetados (entrada y salida conocidas).  
   - Ejemplos:  
     - Clasificaci√≥n (e.g., identificar correos como spam o no spam).  
     - Regresi√≥n (e.g., predecir precios de viviendas).

2. **Aprendizaje No Supervisado**  
   - Trabaja con datos no etiquetados.  
   - Ejemplos:  
     - Clustering (e.g., agrupar clientes por patrones de compra).  
     - Reducci√≥n de dimensionalidad (e.g., resumir grandes conjuntos de datos).

3. **Aprendizaje por Refuerzo**  
   - El modelo aprende a trav√©s de prueba y error en un entorno din√°mico.  
   - Ejemplos:  
     - Juegos (e.g., aprender a jugar ajedrez).  
     - Control rob√≥tico.

4. **Aprendizaje Semi-Supervisado**  
   - Combina datos etiquetados y no etiquetados para mejorar la precisi√≥n.  
   - √ötil cuando etiquetar datos es costoso o dif√≠cil.

5. **Aprendizaje Auto-supervisado**  
   - El modelo genera etiquetas a partir de los datos no etiquetados y aprende sobre ellos.  
   - Ejemplo: t√©cnicas modernas en procesamiento de lenguaje natural como GPT.

### 1.2. Historia de Machine Learning

**Machine Learning (ML)** tiene sus ra√≠ces en el desarrollo de la inteligencia artificial y la estad√≠stica, con hitos clave que han definido su evoluci√≥n:

1. **D√©cada de 1950: Los Inicios**  
   - En 1950, Alan Turing propuso la "M√°quina de Turing" y el famoso "Test de Turing" para evaluar la inteligencia de una m√°quina.  
   - En 1959, Arthur Samuel acu√±√≥ el t√©rmino "Machine Learning", al trabajar en programas que pod√≠an aprender a jugar a las damas mejorando con la experiencia.

2. **D√©cadas de 1960-1980: Bases Te√≥ricas**  
   - Se desarrollaron algoritmos fundamentales, como el perceptr√≥n (precursor de las redes neuronales) y m√©todos estad√≠sticos para clasificaci√≥n.  
   - Limitaciones computacionales y te√≥ricas llevaron al llamado "Invierno de la IA", un per√≠odo de desinter√©s en la investigaci√≥n.

3. **D√©cadas de 1990: Resurgimiento**  
   - El aumento de datos disponibles (Big Data) y la mejora de los sistemas computacionales permitieron un resurgir del inter√©s por ML.  
   - Se popularizaron t√©cnicas como las m√°quinas de soporte vectorial (SVM) y los √°rboles de decisi√≥n.  
   - Apareci√≥ el concepto de "data mining" para extraer patrones √∫tiles de grandes conjuntos de datos.

4. **2000s: Expansi√≥n y Redes Neuronales**  
   - Las redes neuronales comenzaron a ganar popularidad con el auge de la inform√°tica y los algoritmos de aprendizaje profundo (deep learning).  
   - Se aplicaron t√©cnicas de ML en motores de b√∫squeda, reconocimiento de voz e im√°genes, y recomendaciones en l√≠nea.

5. **2010s: Aprendizaje Profundo y Gran Escala**  
   - El aprendizaje profundo revolucion√≥ el campo con arquitecturas como las redes convolucionales (CNN) y recurrentes (RNN).  
   - El uso de GPUs y la disponibilidad de grandes vol√∫menes de datos impulsaron aplicaciones en visi√≥n por computadora, lenguaje natural y conducci√≥n aut√≥noma.  
   - Surgieron plataformas como TensorFlow y PyTorch, democratizando el acceso al desarrollo de modelos de ML.

6. **2020s: Democratizaci√≥n y Modelos Generativos**  
   - Modelos generativos como GPT y DALL¬∑E transformaron la creaci√≥n de contenido.  
   - El aprendizaje auto-supervisado y las arquitecturas multimodales ampliaron el alcance de ML a diversas √°reas.  
   - ML se consolid√≥ como una herramienta fundamental en m√∫ltiples industrias, desde salud hasta finanzas.

**Actualidad:**  
ML contin√∫a evolucionando, integrando avances como la computaci√≥n cu√°ntica y enfoques m√°s sostenibles y √©ticos para el uso de datos.


<br>

### 1.3. Framework de ciencia de datos: herramientas para machine learning

**Terminolog√≠a:**

* Data/Datos: unidades de informaci√≥n o "hechos" de observaciones.
* Features: tipos de informaci√≥n acerca de tus observaciones.
* Filas: observaciones individuales o muestras.
* Columnas: features que describen tus observaciones.
* Outlier: punto(s) de datos o data point(s) que se comporta de forma extra√±a.
* Pre-processing: preparar datos para su uso en un modelo de machine learning.
* ETL pipeline: framework de data science para extraer, transformar y cargar.
* Target: Variable de salida que  te gustar√≠a predecir.

**Tipos de datos:**

* Num√©ricos: su feature es un n√∫mero de tipo entero o flotante.
* Categ√≥rica: sus features representan una clase o tipo; usualmente se representan como un mapeo de n√∫meros o un "one-hot" vector.
* Image: su feature representa una imagen.
* Texto: su feature es en la forma de texto, sea corto (como Twitter) o largo (como en noticias).
* NaN: su feature es desconocido o perdido.

**Proceso de datos categoricos:**

* Convertir datos categoricos en etiquedas Etiqueto a cada tipo de clima con un n√∫mero: "Soleado ‚Äî 1", "Lluvioso ‚Äî 2", "Nublado ‚Äî 3", y "Nevado ‚Äî 4". As√≠ puedo convertir mis datos en n√∫meros.
* Convertir etiquetas en 1 -hot encodings (OHE)
* Pandas ayuda a cargar y analizar datos.
* Histogramas ayudan a ver la distribuci√≥n de un feature.
* Gr√°ficas de dispersi√≥n permiten ver la relaci√≥n entre dos features.

---

## 2. Algoritmos Simples de Machine Learning

### 2.1. La ‚Äúreceta‚Äù para aplicar algoritmos de machine learning

1. Proceso de decisi√≥n: c√≥mo los modelos hacen una predicci√≥n, o retornan una respuesta, usando los par√°metros.
2. Funci√≥n de error/coste: c√≥mo evaluar si los par√°metros en eI modelo generan buenas predicciones.
3. Regla de actualizaci√≥n: c√≥mo mejorar los par√°metros para hacer mejores predicciones (usando optimizaci√≥n num√©rica).

Tambien debemos tomar en cuenta algunos aspectos importantes:

* La normalizaci√≥n: que es estandarizar los datos de cada feature restando a cada dato el promedio y luego dividiendolo con la desviaci√≥n estandar.
* Preparar los datos para el modelo:
    * Training: (60-80%) datos de los que el modelo aprende patrones.
    * Validation: (0-20%) datos que usas para verificar que el modelo aprende.
    * Testing: (0-20%) datos que se apartan para revisar si el modelo fue exitoso al predecir.

### 2.2. Regresi√≥n lineal

üìå La regresi√≥n lineal se utiliza en problemas de predicci√≥n num√©rica a partir de las caracter√≠sticas de los datos.

Sin embargo √©ste algoritmo no funciona bien con datos complejos o que no tienen un comportamiento lineal.

üéØ El objetivo de este algoritmo es encontrar una l√≠nea recta que mejor se ajuste a los datos, en otras palabras que la recta se acerque mas a los datapoints.

* El proceso de decisi√≥n es la combinaci√≥n lineal entre pesos y los valores de entrada (x).
* La funci√≥n de coste nos dice el promedio de que tan buenas o certeras son las predicciones del modelo.
* La regla de actualizaci√≥n es la manipulaci√≥n de los pesos para que logren un mejor ajuste de la l√≠nea de predicci√≥n.

### 2.3. Regresi√≥n log√≠stica

üìå La regresi√≥n log√≠stica es un modelo para resolver problemas de clasificaci√≥n binaria, donde su proceso de decisi√≥n esta dado por la probabilidad de que los par√°metros dado el modelo corresponda a una clase o etiqueta.

### 2.4. √Årboles de Decisi√≥n

Un **√°rbol de decisi√≥n** es una t√©cnica de machine learning que organiza las decisiones como un diagrama en forma de √°rbol. Cada nodo representa una pregunta o condici√≥n sobre los datos, y cada rama una posible respuesta que lleva a una nueva pregunta o a una decisi√≥n final.

#### ¬øC√≥mo Funciona?
1. **Ra√≠z del √Årbol**  
   El √°rbol comienza con una pregunta importante sobre los datos (e.g., "¬øLa temperatura es mayor a 30¬∞C?").  
2. **Nodos Internos**  
   Cada nodo eval√∫a una condici√≥n y ramifica en funci√≥n de las respuestas (e.g., "S√≠" o "No").  
3. **Hojas**  
   Al final de las ramas est√°n las decisiones o predicciones finales (e.g., "Jugar f√∫tbol" o "No jugar f√∫tbol").

#### Proceso de Decisi√≥n
El √°rbol utiliza las caracter√≠sticas de los datos para dividirlos en grupos m√°s simples. Esto se hace buscando la divisi√≥n que minimice la **impureza**, es decir, que agrupe mejor los datos similares.  
- **Impureza**: mide qu√© tan mezclados est√°n los datos en un grupo. Ejemplos comunes:
  - *Gini*: mide cu√°n puros son los grupos.
  - *Entrop√≠a*: mide el desorden en los datos.

### 2.5. Aprendizaje No Supervisado

El **aprendizaje no supervisado** es un tipo de machine learning donde el modelo trabaja con datos que no tienen etiquetas o categor√≠as predefinidas. Su objetivo es encontrar patrones o estructuras ocultas en los datos.

#### ¬øC√≥mo Funciona?  
1. **Entrada**  
   Solo se proporcionan los datos sin decirle al modelo qu√© buscar.  
2. **Procesamiento**  
   El modelo organiza los datos seg√∫n similitudes o diferencias.  
3. **Salida**  
   Produce agrupaciones, patrones o nuevas representaciones de los datos.

---

## 3. Redes Neuronales

### 3.1. Redes Neuronales

Las **redes neuronales** son modelos inspirados en el cerebro humano que procesan informaci√≥n a trav√©s de nodos (neuronas) conectados en capas. Son herramientas poderosas para resolver problemas complejos como reconocimiento de im√°genes, traducci√≥n autom√°tica o predicci√≥n de tendencias.

#### ¬øC√≥mo Funcionan?  
1. **Capas de la Red**  
   - **Capa de entrada**: recibe los datos iniciales (e.g., p√≠xeles de una imagen).  
   - **Capas ocultas**: procesan los datos aplicando c√°lculos matem√°ticos (transformaciones no lineales).  
   - **Capa de salida**: entrega el resultado final (e.g., "Gato" o "Perro").  

2. **Proceso**  
   Los datos pasan por cada capa, y las neuronas aplican pesos ($w$) y sesgos ($b$) para calcular un valor, seguido por una funci√≥n de activaci√≥n (e.g., ReLU o Sigmoid) que introduce no linealidad.


### 3.2. C√≥mo Mejorar las Predicciones de Redes Neuronales

1. **Hiperpar√°metros √ìptimos**  
   - Ajustar la tasa de aprendizaje ($\alpha$).  
   - Determinar el n√∫mero de capas y neuronas por capa.  
   - Usar t√©cnicas como *dropout* para evitar sobreajuste.

2. **Mayor y Mejor Calidad de Datos**  
   - M√°s datos relevantes ayudan a la red a generalizar mejor.  
   - Preprocesar los datos para normalizarlos o eliminar ruido.

3. **Arquitectura Adecuada**  
   - Elegir el dise√±o de red correcto seg√∫n el problema (e.g., CNN para im√°genes, RNN para datos secuenciales).  

4. **Regularizaci√≥n**  
   - Aplicar penalizaciones para evitar que la red se ajuste demasiado a los datos de entrenamiento.  

5. **Entrenamiento con M√°s Iteraciones**  
   - Incrementar las √©pocas de entrenamiento (con cuidado para no sobreajustar).


### 3.3. Entrenamiento de Redes Neuronales

1. **Propagaci√≥n hacia Adelante (Forward Propagation)**  
   - Los datos ingresan por la capa de entrada y se transforman a trav√©s de las capas hasta generar una predicci√≥n en la capa de salida.

2. **C√°lculo de Error**  
   - Comparar la predicci√≥n con el valor real usando una funci√≥n de p√©rdida (e.g., MSE para regresi√≥n, entrop√≠a cruzada para clasificaci√≥n).

3. **Propagaci√≥n hacia Atr√°s (Backward Propagation)**  
   - Calcular los gradientes del error con respecto a los pesos y sesgos usando el algoritmo de *backpropagation*.  
   - Actualizar los pesos y sesgos con el m√©todo de **descenso de gradiente**:
     $$
     w = w - \alpha \frac{\partial L}{\partial w}
     $$  
     Donde:
     - $L$: funci√≥n de p√©rdida.  
     - $\alpha$: tasa de aprendizaje.  

4. **Repetici√≥n**  
   - El proceso de propagaci√≥n hacia adelante y atr√°s se repite durante varias √©pocas hasta que el error sea m√≠nimo o el modelo converja.

#### Importante  
El √©xito del entrenamiento depende de encontrar el equilibrio entre un modelo que aprende lo suficiente de los datos sin ajustarse demasiado a ellos (sobreajuste).

