# FUENTES Y TIPOS DE RUIDO

## 1. Entrop√≠a

La ``entrop√≠a``, en el contexto de la teor√≠a de la informaci√≥n, ``cuantifica la incertidumbre o aleatoriedad`` de una se√±al. Se refiere a ``cu√°nta informaci√≥n promedio`` produce una ``fuente aleatoria``.

Desde el punto de vista de una se√±al digital, ``mayor entrop√≠a implica mayor desorden o complejidad``, lo cual a menudo est√° relacionado con la ``presencia de ruido``.

> En t√©rminos sencillos: cuanto m√°s impredecible es una se√±al, ``mayor es su entrop√≠a``.

### üìå¬øPor qu√© es importante la entrop√≠a?

- ``Permite caracterizar la complejidad`` de una se√±al.
- ``Eval√∫a el impacto del ruido`` en una se√±al.
- Es √∫til para ``detectar patrones o la falta de ellos``.
- Se usa en compresi√≥n de datos, detecci√≥n de anomal√≠as, y an√°lisis de se√±ales.

### üìåEntrop√≠a de Shannon (definici√≥n matem√°tica)

Para una variable aleatoria discreta $X$ que toma valores $x_1, x_2, ..., x_n$ con probabilidades $P(x_1), P(x_2), ..., P(x_n)$, la **entrop√≠a de Shannon** se define como:

$$
H(X) = - \sum_{i=1}^n P(x_i) \log_2 P(x_i)
$$

- Si un valor tiene **alta probabilidad**, su contribuci√≥n a la entrop√≠a es **menor**.
- Si tiene **baja probabilidad**, su **efecto sorpresa** es mayor, y por tanto contribuye m√°s.

### üé≤ Ejemplo: Distribuci√≥n de Bernoulli

Para una variable con dos posibles valores (√©xito/fracaso), la entrop√≠a es:

$$
H(p) = -p \log_2 p - (1-p) \log_2 (1-p)
$$

- **M√°ximo** en $p = 0.5$ ‚Üí m√°xima incertidumbre.
- **M√≠nimo** en $p = 0$ o $p = 1$ ‚Üí certeza total.

### üìåSe√±ales como procesos estoc√°sticos

Una se√±al puede verse como una **secuencia de variables aleatorias** dependientes del tiempo (series temporales) o del espacio (como en im√°genes).

Por tanto, se puede extender el c√°lculo de entrop√≠a al caso de se√±ales con m√∫ltiples variables:

$$
H(X_1, X_2, ..., X_N) = - \sum P(x_1, x_2, ..., x_n) \log_2 P(x_1, x_2, ..., x_n)
$$

Y el **ratio de entrop√≠a** o entrop√≠a media por muestra es:

$$
h = \frac{H(X_1, ..., X_N)}{N}
$$

### üìåEstimaci√≥n de la entrop√≠a: Entrop√≠a Aproximada (ApEn)

Dado que calcular la entrop√≠a exacta puede ser dif√≠cil para se√±ales reales, se usan **m√©todos de estimaci√≥n**, como la **Entrop√≠a Aproximada (ApEn)**.

### üß© Pasos del m√©todo:

1. Dada una se√±al $S = [x_1, x_2, ..., x_N]$, se extraen todas las subseries de longitud $m$:  
   $$
   \mathbf{u}(i) = [x_i, x_{i+1}, ..., x_{i+m-1}]
   $$

2. Se define una **tolerancia $r$** para decidir si dos subseries son similares:  
   $$
   d[\mathbf{u}(i), \mathbf{u}(j)] \le r
   $$

3. Se calcula la **proporci√≥n de subseries similares a cada subserie**:
   $$
   C_i^m(r) = \frac{\text{N√∫mero de subseries similares a } \mathbf{u}(i)}{N - m + 1}
   $$

4. Se obtiene el promedio:
   $$
   \phi^m(r) = \frac{1}{N - m + 1} \sum_{i=1}^{N - m + 1} \ln C_i^m(r)
   $$

5. Finalmente, la **entrop√≠a aproximada** es:
   $$
   ApEn(m, r, N) = \phi^m(r) - \phi^{m+1}(r)
   $$

## üìåEntrop√≠a en im√°genes

En im√°genes, no hay una dimensi√≥n temporal. En su lugar:

- Se mide la **distribuci√≥n de intensidad** en dos dimensiones (espacio).
- Se utiliza el **histograma** de intensidades como estimador de la funci√≥n de probabilidad.

$$
H = - \sum_{i=0}^{255} P(i) \log_2 P(i)
$$

- **Im√°genes con patrones repetitivos** (como texturas) ‚Üí menor entrop√≠a (histograma con picos).
- **Im√°genes con ruido o alta variabilidad** ‚Üí mayor entrop√≠a (histograma plano).

### üìåRelaci√≥n entre entrop√≠a y ruido

- **Mayor entrop√≠a = Mayor ruido** (m√°s impredecible).
- Si medimos una misma se√±al varias veces, aquella con **mayor entrop√≠a** ser√° la m√°s contaminada por ruido.

Esto se cumple tanto para se√±ales unidimensionales (voz, ECG) como bidimensionales (im√°genes).

### üìåConclusiones clave

- La **entrop√≠a mide la incertidumbre**, no solo la cantidad de datos.
- Es √∫til para saber cu√°n **compleja o ruidosa** es una se√±al.
- Aporta un marco cuantitativo para comparar se√±ales o im√°genes en t√©rminos de **calidad, compresi√≥n o limpieza**.
- Es una herramienta fundamental en **teor√≠a de la informaci√≥n, procesamiento de se√±ales e inteligencia artificial**.

---

## 2. ‚õ≤ Fuentes perturbadoras de las se√±ales

Las se√±ales el√©ctricas que viajan por los sistemas de comunicaci√≥n o procesamiento de datos pueden verse afectadas por diferentes tipos de ruido. A continuaci√≥n, se describen las principales fuentes perturbadoras clasificadas seg√∫n su origen.

### Clasificaci√≥n de los tipos de ruido

Las se√±ales el√©ctricas se ven afectadas por diferentes tipos de ruido que pueden clasificarse de la siguiente manera:

### 1. Ruido atmosf√©rico

El **ruido atmosf√©rico** proviene de se√±ales el√©ctricas generadas por fen√≥menos naturales, principalmente descargas el√©ctricas en la atm√≥sfera, como tormentas o cargas en las nubes. 

- Tiene un impacto m√°s notorio en sistemas que usan el espectro radioel√©ctrico como canal.
- Su potencia es **inversamente proporcional a la frecuencia**: afecta m√°s a bandas de baja y media frecuencia (como AM).
- Disminuye en frecuencias altas (VHF, UHF, TV, FM).
- A partir de los **30 MHz**, su impacto es menor comparado con el ruido del propio receptor.

### 2. Ruido producido por el hombre (Ruido industrial)

Este tipo de ruido es generado por artefactos el√©ctricos artificiales, como:

- Motores el√©ctricos  
- Autom√≥viles  
- L√≠neas de alto voltaje  
- Interruptores, etc.

Este **ruido industrial**:

- Es m√°s intenso en **zonas urbanas o industriales**.
- Afecta principalmente el rango de **1 MHz a 600 MHz**.
- Es una de las principales fuentes de interferencia en medios urbanos.

### 3. Ruido impulsivo (o Shot noise)

El **ruido impulsivo** se caracteriza por:

- La aparici√≥n de valores an√≥malos o *outliers*.
- Aumentos bruscos de intensidad durante per√≠odos cortos de tiempo.
- Es producido por **eventos puntuales**, como rayos o chispas en motores.

> Aunque se origina fuera del sistema, no debe confundirse con el ruido atmosf√©rico o industrial, ya que su duraci√≥n es m√°s breve y puntual.

### 4. Ruido gal√°ctico

Proviene de perturbaciones m√°s all√° de la atm√≥sfera terrestre. Sus dos fuentes principales son:

#### a. Solar

- El **Sol** emite radiaci√≥n electromagn√©tica en un amplio espectro de frecuencias.
- Afecta a los sistemas de comunicaci√≥n por radio.
- Su intensidad **var√≠a c√≠clicamente** con un periodo de unos 11 a√±os.
- En picos altos puede inutilizar ciertas bandas de comunicaci√≥n.

#### b. C√≥smico

- Otras **estrellas** cercanas al planeta tambi√©n emiten radiaci√≥n electromagn√©tica.
- Pueden interferir con las se√±ales, aunque en menor medida que el Sol.

### 5. Ruido t√©rmico (Johnson‚ÄìNyquist)

Causado por la **agitaci√≥n t√©rmica de los electrones** en los conductores o componentes electr√≥nicos.

- Est√° **presente siempre** que haya temperatura mayor a 0 K.
- A mayor temperatura, mayor agitaci√≥n electr√≥nica.
- Se distribuye a lo largo de **todo el espectro de frecuencias**.
- No se puede eliminar totalmente, aunque puede atenuarse con filtrado.

### 6. Ruido de parpadeo (Flicker Noise o 1/f)

- Tambi√©n llamado **ruido 1/f** por su comportamiento: su potencia decrece con el aumento de frecuencia.
- Es m√°s intenso en **bajas frecuencias (por debajo de 1 kHz)**.
- A√∫n se investigan sus causas, pero se presenta en:
  - Transistores
  - Resistencias
- Se asocia a **procesos de intermodulaci√≥n** dentro de los materiales.

### üìåRelaci√≥n Se√±al a Ruido (SNR - Signal to Noise Ratio)

Cuando una se√±al es afectada por ruido, se puede cuantificar su calidad mediante la **relaci√≥n se√±al a ruido (SNR)**, que se define como:

$$
\text{SNR} = \frac{P_\text{se√±al}}{P_\text{ruido}}
$$

Donde:

- $P_\text{se√±al}$: Potencia de la se√±al √∫til.
- $P_\text{ruido}$: Potencia del ruido presente.

Para mayor claridad, la SNR se expresa en **decibelios (dB)**:

$$
\text{SNR}_{dB} = 10 \cdot \log_{10} \left( \frac{P_\text{se√±al}}{P_\text{ruido}} \right)
$$

- Un valor alto de SNR indica que la se√±al sobresale respecto al ruido.
- Un SNR bajo puede significar p√©rdida de informaci√≥n o mala calidad de transmisi√≥n.

### üìåDiferencia entre ruido y entrop√≠a

| Concepto | Explicaci√≥n                                                                                                                |
| -------- | -------------------------------------------------------------------------------------------------------------------------- |
| Entrop√≠a | Es una propiedad de la fuente de informaci√≥n. Mide cu√°nta incertidumbre (o cu√°nta sorpresa) tiene un mensaje.              |
| Ruido    | Es una interferencia ajena al mensaje original. No viene de la fuente, sino del canal o el medio por donde viaja la se√±al. |

**üéØ Entonces, para aclarar:**

* Una fuente con alta entrop√≠a puede ser una fuente leg√≠tima de informaci√≥n, aunque muy impredecible. Por ejemplo, un generador de contrase√±as aleatorias.
* Pero cuando una se√±al pasa por un canal (como un cable, el aire, un sistema de transmisi√≥n), puede mezclarse con ruido.
* Ese ruido puede ser aleatorio, s√≠. Y por eso puede tener entrop√≠a.
* Sin embargo, la entrop√≠a del ruido y la entrop√≠a de la se√±al son cosas diferentes.

---

## 3. üìö Caracterizaci√≥n Matem√°tica del Ruido: Procesos Estoc√°sticos

Un proceso estoc√°stico es un modelo que usamos para representar cosas que cambian de forma aleatoria en el tiempo, como el ruido.

En nuestro contexto:
- Una se√±al observada = **se√±al de inter√©s** + **ruido** (no deseado y aleatorio).
- El ruido genera **entrop√≠a**, imprevisibilidad y variabilidad.
- Por lo tanto, la se√±al observada es una **realizaci√≥n de un proceso estoc√°stico**.

### üî¢ Componentes de un proceso estoc√°stico

1. **Espacio muestral (Œ©)**  
   Todos los posibles resultados del experimento.

2. **Conjunto de sucesos (F)**  
   Subconjuntos del espacio muestral (eventos posibles).

3. **Ley de probabilidad (P)**  
   Asigna probabilidades a los sucesos.

üß† Anal√≥gicamente, es como una variable aleatoria, pero devuelve **una se√±al** completa, no un n√∫mero.

### üß™ Ejemplo de se√±al ruidosa

Supongamos:
- $S(t)$: se√±al de inter√©s (senoidal de frecuencia $f$)
- $N(t)$: ruido con distribuci√≥n gaussiana, media 0, varianza $\sigma^2$

Entonces:

$$
X(t) = S(t) + N(t)
$$

üìà El ruido hace que la se√±al resultante sea aleatoria e impredecible.

### üìä Funciones estad√≠sticas importantes

1. **Funci√≥n de distribuci√≥n** $F_X(x)$:  
   Probabilidad acumulada de que $X(t) \leq x$

2. **Funci√≥n de densidad de probabilidad** $f_X(x)$:  
   Describe c√≥mo se distribuyen los valores de la se√±al

### üîÅ Estacionariedad

- Un proceso es **estacionario en sentido estricto** si su funci√≥n de densidad de probabilidad **no cambia en el tiempo**:

$$
f_{X(t_1), X(t_2),...,X(t_n)} = f_{X(t_1 + c), X(t_2 + c),...,X(t_n + c)}
$$

- Es **estacionario en sentido amplio** si sus **momentos estad√≠sticos** (media, varianza, covarianza) son **constantes** en el tiempo.

### ‚ö†Ô∏è Ejemplo de no estacionariedad

Si una se√±al presenta una **tendencia temporal** (como una subida constante), su media y varianza cambian:

- No es estacionaria.
- Debe corregirse eliminando esa tendencia.

### ‚úÖ Conclusi√≥n

- Las se√±ales ruidosas deben modelarse como **procesos estoc√°sticos**.
- Las funciones estad√≠sticas permiten analizarlas y filtrarlas.
- La **estacionariedad** es clave para su an√°lisis y tratamiento adecuado.
